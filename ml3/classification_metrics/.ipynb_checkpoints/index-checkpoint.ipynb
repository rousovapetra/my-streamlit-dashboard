{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Klasifikační metriky "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Úloha klasifikace je trochu jiná než úloha regrese, proto má své vlastní metody na posuzování úspěšnosti modelů. \n",
    "Projdeme nejdůležitější metriky určené pro klasifikaci.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Abychom mohli metriky rovnou ilustrovat na příkladu, vezměme si na pomoc známou datovou množinu **Iris**.\n",
    "Jedná se o klasifikaci květů (amerických) kosatců. Datovou množinu ve třicátých letech sestavil statistik a biolog Ronald Fisher (viz [wiki](https://en.wikipedia.org/wiki/Iris_flower_data_set)). \n",
    "Množina obsahuje tři třídy: *setosa*, *versicolor* a *virginica*.\n",
    "![iris_data](static/iris_data.png)\n",
    "\n",
    "Na dalším obrázku vidíte pairplot zobrazující závislosti mezi dvojicemi příznaků (vstupními proměnnými) a výslednou třídou. Barva tečky odpovídá třídě, do které daný kosatec patří. Vidíte např. že červená třída *setosa* se dá určit dle velkosti okvětního (petal lístku).\n",
    "\n",
    "![iris_pairplot](static/iris_pairplot.jpg)\n",
    "\n",
    "Cílem úlohy je vytvořit model -- klasifikátor, který nám pro dané hodnoty kališních (sepal) a okvětních (petal) lístků vrátí správné zařazení daného vzorku do třídy. \n",
    "Jako klasifikátor zvolme rozhodovací strom, t. j. *DecisionTreeClassifier*. (Je to jeden z nejznámějších klasifikátorů, oblíbený zejména díky své rychlosti a snadné interpretovatelnosti. Více si o něm můžeš přečíst na [wiki](https://en.wikipedia.org/wiki/Decision_tree)).  \n",
    "Nás tedy bude zajímat, jak můžeme měřit úspěšnost našeho klasifikátoru. \n",
    "\n",
    "(Data tentokrát nečteme ze souboru, ale použijeme předpřipravená data z modulu [datasets](https://scikit-learn.org/stable/api/sklearn.datasets.html) knihovny Scikit-learn). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tohle tu máme jen proto, aby všechny výpočty proběhly stejně \n",
    "# nastavení náhodného generátoru \n",
    "import numpy as np\n",
    "np.random.seed(42)\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from  sklearn import  datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "iris = datasets.load_iris()   # načteme si data, Iris data jsou \"vestavěná\"\n",
    "X = iris.data                 # příznaky \n",
    "y = iris.target               # třídy (labely)\n",
    "classes = iris.target_names\n",
    "\n",
    "# rozdělme data na trénovací a testovací \n",
    "# random_state určuje inicializaci generátoru náhodných čísel (chceme aby nám to vždy vyšlo stejně) \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.2, random_state=314)\n",
    "\n",
    "# vytvořme klasifikátor \n",
    "klasifikator = DecisionTreeClassifier()\n",
    "\n",
    "# natrénujeme a ohodnotíme testovací množinu \n",
    "klasifikator.fit(X_train, y_train)\n",
    "y_pred = klasifikator.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podívejme se, jak predikce vypadají."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_compare = (\n",
    "    pd.DataFrame()\n",
    "    .assign(skutecna_trida=y_test)\n",
    "    .assign(predikovana_trida=y_pred)\n",
    "    .replace({i: name for i, name in enumerate(classes)})\n",
    ")\n",
    "df_compare[\"spravne?\"] = (df_compare[\"skutecna_trida\"] == df_compare[\"predikovana_trida\"]).replace(\n",
    "    {True: \"OK\", False: \":(\"}\n",
    ")\n",
    "df_compare.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nejjednodušší, co můžeme měřit, je procento správných odpovědí. Tomu se říká **accuracy**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "100 * ((y_pred == y_test).sum() / len(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Metriku ale nemusíš sama programovat, k výpočtu **accuracy** nabízí knihovna Scikit-learn funkci `accuracy_score`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Úkol: \n",
    "\n",
    "Představ si, že máš klasifikovat jablka a hrušky. Máš datovou množinu obsahující 100 kusů ovoce. \n",
    "Klasifikátor na této množině dosahuje úspěšnosti 90% (90 kusů je klasifikováno správně). Myslíš, že takový \n",
    "klasifikátor je dobrý? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Accuracy** nám dává velmi málo informace. Prozradíme si nyní, že v úkolu \n",
    "s ovocem bylo 90 kusů jablek a 10 kusů hrušek. Klasifikátor, který vše, co dostane, označuje\n",
    "za jablko, má tedy na této množině 90% úspěšnost. Nám je ale k ničemu. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podíváme se na zajímavější metriku a tou je **confusion matrix**, česky **matice záměn**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "\n",
    "display = ConfusionMatrixDisplay.from_predictions(\n",
    "    y_test, y_pred,\n",
    "    display_labels=iris.target_names                              \n",
    ")\n",
    "display.plot();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Matice záměn (**confusion matrix**) nám dává daleko více informace. Na obrázku vidím, \n",
    "kolik vzorků z třídy dané řádkem bylo klasifikováno do třídy dané sloupcem.\n",
    "\n",
    "Tedy v našem případě: Jeden vzor typu Virginica byl oklasifikován chybně jako Versicolor, dva vzory typu Versicolor byly oklasifikovány chybně jako Virginica. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metriky pro binární klasifikaci"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nyní se podíváme na binární klasifikaci (klasifikaci do dvou tříd). Vezměme si data *breast_cancer*, která obsahují\n",
    "pozitivní a negativní rakovinové nálezy. \n",
    "Abychom měli srovnání různých řešení, vezmeme si dva klasifikátory, jednak SVC (*Support Vector Machine* klasifikátor, česky metoda podpůrných vektorů, ale český název se nepoužívá. Více informací viz [wiki](https://cs.wikipedia.org/wiki/Support_vector_machines)) a pak tzv. *Dummy* klasifikátor, který slouží pouze jako baseline a implementuje triviální řešení. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "# natáhneme data a rozdělíme na trénovací a testovací\n",
    "X, y = datasets.load_breast_cancer(return_X_y=True)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0, stratify=y)\n",
    "\n",
    "# vytvoříme a natrénujeme klasifikátory \n",
    "klasifikator = SVC(probability=True) # probability=True zajišťuje pozdější možnost použití metody predic_proba\n",
    "klasifikator.fit(X_train, y_train)\n",
    "\n",
    "dummy = DummyClassifier()\n",
    "dummy.fit(X_train, y_train)\n",
    "\n",
    "# oklasifikujeme si testovací vzorky \n",
    "y_pred = klasifikator.predict(X_test)\n",
    "y_dummy = dummy.predict(X_test)\n",
    "\n",
    "# spočteme accuracy\n",
    "print(\"SVC accuracy \", accuracy_score(y_test, y_pred))\n",
    "print(\"dummy accuracy \", accuracy_score(y_test, y_dummy))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Podívejme se, jak vypadají predikce:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "klasifikator.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nemělo by nás překvapit, že dummy klasifikátor predikuje vše jako většinovou třídu. Je to hloupý klasifikátor, který jde cestou nejmenšího odporu. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pro více informace, můžeme použít metodu `predict proba`, která vrátí pro každou třídu stupeň náležení do dané třídy. Zobrazme si např. hned první vzorek:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "klasifikator.predict_proba(X_test[0:1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vzorek zařadíme do první třídy (pozitivní nález), můžeme též říci, že do této třídy patří s pravděpodobností cca 0.7. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I při binární klasifikaci se může hodit matice záměn. Zobrazme si ji."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(10, 3))\n",
    "\n",
    "ConfusionMatrixDisplay.from_predictions(\n",
    "    y_test, klasifikator.predict(X_test), ax=ax[0]\n",
    ")\n",
    "ax[0].set_title(\"Rozhodovací strom\")\n",
    "\n",
    "ConfusionMatrixDisplay.from_predictions(\n",
    "    y_test, dummy.predict(X_test), ax=ax[1]\n",
    ")\n",
    "ax[1].set_title(\"Dummy klasifikátor\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Třídu 0 označujeme jako negativní, třídu 1 jako positivní. Dva pozitivní vzorky byly označeny za negativní, \n",
    "takovýmto případům říkáme falešně negativní (**false negative**). Deset negativních vzorků bylo označeno jako positivní, to jsou tzv. falešně positivní (**false positive**) vzory. U dummy klasifikátoru je naopak vše označeno za pozitivní, máme tedy 53 falešně negativních vzorků.\n",
    "\n",
    "Počty falešně positivních a falešně negativních případů jsou pro hodnocení úspěšnosti binární klasifikace zásadní. \n",
    "Správně klasifikované vzorky označujeme jako **true positive** a **true negative**. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obrázek níže ilustruje rozdělní vzorků na **true positive**, **true negative**, **false negative** a **false positive**. Oranžová barva reprezentuje pozitivní vzorky, modrá negativní. Vzorky uvnitř kola označil klasifikátor jak pozitivní (zelená oblast je správně klasifikovaná,  tedy **true positive**, a červená špatně klasifikovaná, **false positive**).  Vzorky vně kola, označil klasifikátor jako negativní. Oranžové vně kola jsou tedy **false negative**, modré vně kola jsou **true negative**.  \n",
    "\n",
    "![obrazek_true_false_positive_negative](static/np_2025.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Precision, recall, F1 skóre"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Klasifikační metrika známá jako **precision** říká, kolik vzorků označených za pozitivních je opravdu pozitivních. \n",
    "\n",
    "![precision](static/precision.png)\n",
    "\n",
    "TP označuje počet správně označených pozitivních vzorků (**true positives**) <br>\n",
    "FP označuje počet falešně pozitivních vzorků (**false negatives**) \n",
    "\n",
    "Metrika **recall** říká, kolik pozitivních vzorků bylo podchyceno klasifikátorem (klasifikováno jako pozitivní).\n",
    "\n",
    "![recall](static/recall.png)\n",
    "\n",
    "P je počet všech pozitivních vzorků, ten se rozpadá na TP (**true positives**) a FN (**false negatives**).\n",
    "\n",
    "Nesnaž se vzorečky zapamatovat, zamysli se nad tím, co nám říkají. S tím ti pomůže obrázek výše a následující příklad z [Wikipedie](https://en.wikipedia.org/wiki/Precision_and_recall). \n",
    "\n",
    "Představ si, že máš počítačový program na rozpoznávání psů na fotografiích. Máš fotku 12 psů a několika koček.\n",
    "Program ti na fotografii najde 8 psů. Pět z těchto 8 psů jsou opravdu psi (**true positive**), ale zbylí dva jsou ve skutečnosti kočky (**false positive**). **Precision** programu je 5/8 (0.625), zatímco **recall** je 5/12 (cca 0.417). **Precision** se dá interpretovat jako míra užitečnosti výsledku, **recall** říká, jak moc je výsledek kompletní (kolik psů z těch co jsme chtěli najít, jsme opravdu našli).  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Knihovna Scikit-learn má pro tebe samozřejmě připravené funkce na výpočet těchto *precision* a *recall*, zobrazme si je tedy pro náš rozhodovací strom a pro dummy klasifikátor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score\n",
    "\n",
    "print(\"DecisionTree\")\n",
    "print(\"Precision: \", precision_score(y_test, y_pred))\n",
    "print(\"Recall:    \", recall_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Dummy\")\n",
    "print(\"Precision: \", precision_score(y_test, y_dummy))\n",
    "print(\"Recall:    \", recall_score(y_test, y_dummy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zda je pro nás důležitější precision nebo recall, záleží na konkrétní úloze. \n",
    "Někdy vadí více falešně pozitivní případy (příliš mnoho relevantních mailů označených za spam), \n",
    "jindy bude více vadit nezachycený pozitivní případ (neodhalený výskyt nemoci). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Další často používanou metrikou je tzv. **F1 skóre**. Kombinuje *precision* a *recall*, a to tak, že obě tyto metriky mají stejnou váhu (Přispívají stejnou měrou k výsledku). Čím větší hodnota, tím lepší výsledek. Maximální hodnota je jedna, minimální 0.\n",
    "\n",
    "![F1](static/f1.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "print(\"F1 skóre SVC:    \", f1_score(y_test, y_pred))\n",
    "print(\"F1 skṕre Dummy:    \", f1_score(y_test, y_dummy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ROC křivka"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Další užitečná charakteristika je tzv. ROC křivka ([wiki](https://cs.wikipedia.org/wiki/ROC_k%C5%99ivka)). Název pochází z anglického Receiver Operating Characteristic, operační charakteristika přijímače.  Křivka vyjadřuje kvalitu binárního klasifikátoru v závislosti \n",
    "na klasifikačním prahu. \n",
    "\n",
    "Co je to klasifikační práh? Představ si, že v úloze na `breast cancer` nebude naučený model vracet hodnoty 0/1 (negativní, pozitivní nález), ale číslo typu `float` udávající pravděpodobnost (nebo nějakou míru) náležení do pozitivní třídy.\n",
    "\n",
    "V nejjednodušším případě budeš vzorky s pravděpodobností větší než 0.5 klasifikovat jako pozitivní,  ostatní jako negativní. Můžeš ale chtít být opatrná a dovyšetřit i pacienty, kteří mají horší nález, i když ne tak špatný, aby model dával odezvu větší než 0.5. Pak tento práh nebude 0.5, ale např. 0.4. Můžeš být zastánce přístupu \"nejhorší je smrt z vystrašení\" a rozhodneš se dovyšetřit jen pacienty s opravdu špatným nálezem. Pak nastavíš práh např. na 0.7. Jaký přístup je potřeba záleží na konkrétní situaci. \n",
    "\n",
    "ROC křivka zobrazuje vztah mezi pravděpodobností detekce (**true positive rate**, senzitivita, recall) TPR a pravděpodobností falešného poplachu (**false positive rate**) FPR. \n",
    "\n",
    "![roc](static/roc.png)\n",
    "\n",
    "P, N ... jsou počty všech pozitivních/negativních vzorků \n",
    "\n",
    "ROC křivka zobrazuje na ose x pravděpodobnost falešného poplachu, na ose y pravděpodobnost detekce. Toto pro všechny klasifikační prahy. Čím vyšší klasifikační práh, tím nižší pravděpodobnost falešného poplachu i nižší senzitivita. Čím menší klasifikační práh, tím větší pravděpodobnost detekce (senzitivita) i větší nebezpečí falešného poplachu. \n",
    "\n",
    "Čím je křivka blíže hornímu levému rohu, tím pro klasifikátor lépe. Naprosto ideální situace by byla, TPR = 1.0, tedy všechny pozitivní vzorky jsou klasifikovány jako pozivní, a FPR = 0.0, žádný z negativních není klasifikován jako pozitivní."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import RocCurveDisplay\n",
    "\n",
    "ax = plt.subplot() \n",
    "klasifikator_disp = RocCurveDisplay.from_estimator(klasifikator, X_test, y_test, ax=ax)\n",
    "dummy_disp = RocCurveDisplay.from_estimator(dummy, X_test, y_test, ax=ax)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hodnota AUC (Area Under the Curve) udává obsah plochy pod ROC křivkou. Čím větší plocha, tím lepší klasifikátor.  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
